<html>
    <head>
        <title>InfoCon</title>
        <meta charset="UTF-8">
        <meta name="viewport" content="witdh=device-width, initial-scale=1.0">
        <style>
            body {
                font-family: "Arial";
            }
            table {
                width: 100%;
                border-collapse: collapse;
            }

            th, td {
                border: 20px solid rgb(255,255,255);
                background-color: rgb(220,220,220);
                padding: 8px;
                /* padding: 10px; */
                text-align: left;
                vertical-align: top;
            }

            .first-column {
                width: 600px;
            }
        </style>
    </head>

    <body>
    
    <!-- Title -->
    <table>
    <tr>
    <th colspan="2">
    <font size=8px> InfoCon: Concept Discovery with Generative and Discriminative Informativeness</font><br/>
    <font size=4px>&#x270D;&#xFE0F; Ruizhe Liu, Qian Luo, Yanchao Yang</font><br/>
    <font size=4px>&#x1F517; <a href="" target="_blank">[codes]</a><a href="https://openreview.net/pdf?id=g6eCbercEc" target="_blank">[paper]</a></font>
    </th>
    </tr>
    </table>
    <br/>
    <!-- Title End-->

    <!-- Introduction -->
    <table>
    <tr>
    <th colspan="2">
    <font size=6px>Introduction</font>
    </th>
    </tr>

    <tr>
    <td>
    <font size=5px> <b>Discovery of Goals as Manipulation Concepts</b> </font><br/><br/>
    <font size=3px>
    Our research endeavors to discover manipulation concepts
    that characterize the goal an agent aim to fulfill at a specific juncture
    while interacting with the environment.<br/><br/>
    When provided with a dataset comprising demonstration trajectories of manipulation tasks,
    we are capable of segmenting these trajectories into distinct stages
    and assigning each stage with a unique label derived from a learnable codebook.
    This codebook serves as the symbolic representation of the goals,
    encapsulating the manipulation concepts we aim to uncover.
    </font>
    </td>
    <td>
    <img src="imgs/infocon.png" width="600px"/>
    </td>
    </tr>

    <tr>
    <td>
    <font size=5px> <b>Model of Goal</b></font><br/><br/>
    <font size=3px>
    There are a myriad of methods to unearth latent knowledge from data.
    However, the question still remains: <b>How can we ascertain that it aligns with a 'goal'?</b>
    The essence of this inquiry is encapsulated in our understanding of <b>What constitutes a 'goal'?</b><br/><br/>
    Our research introduces two innovative concepts designed to ensure that the latent knowledge we uncover closely resembles a goal.<br/><br/>
    To encapsulate, the <b>Generative Goal</b> is indicative of the state that signifies the attainment of the goal.
    The <b>Discriminative Goal</b> assesses the appropriateness and completeness of a goal, thereby offering directional guidance.
    </font>
    </td>
    <td class="first-column">
    <img src="imgs/gg_and_dg.jpg" width="600px"/>
    </td>
    </tr>

    <tr>
    <td>
    <font size=5px> <b>Self-Supervised Discovery of Manipulation Concepts</b></font><br/><br/>
    <font size=3px>
    Utilizing a VQVAE architecture,
    we have the capability to assign a specific label from the VQ codebook to
    every state within a demonstration trajectory.<br/><br/>
    Subsequently, leveraging the label proposed,
    we employ a self-supervised mechanism to
    refine the label assignments from the VQ codebook,
    thereby enhancing the segmentation of the trajectory.
    In this context, we utilize two predictive models to ensure that the
    latent manipulation concepts align with the definition of the Generative Goal and Discriminative Goal.
    </font>
    </td>
    <td class="first-column">
    <img src="imgs/pipeline.png" width="600px"/>
    </td>
    </tr>

    </table>
    <br/>
    <!-- Introduction End-->

    <!-- Experiments -->
    <table>
    
    <tr>
    <th colspan="2">
    <font size=6px>Experiments on Manipulation Tasks</font>
    </th>
    </tr>

    <tr>
    <td>
    <font size=5px> <b>Evaluation based on CoTPC</b></font><br/><br/>
    <font size=3px>
    <a href="https://zjia.eng.ucsd.edu/cotpc" target="_blank">CoTPC</a> can help us evaluate the effectiveness of manipulation concepts discovered by InfoCon.<br/><br/>
    CoTPC can improve performance of behavior cloning on manipulation tasks
    by learning to predict control and action along with what called key states.
    Here key states can be regarded as achievement of a certain sub-goal.<br/><br/>
    Original work of CoTPC relies on the semantic label of key states, aligning with human intuition.
    We can just change the key states to the ones discovered by InfoCon,
    to see whether the concepts of InfoCon is more helpful.
    </font>
    </td>
    <td class="first-column">
    <img src="imgs/cotpc.png" width="600px"/>
    <br/><br/>From paper <a href="https://arxiv.org/abs/2304.00776" target="_blank">https://arxiv.org/abs/2304.00776</a>
    </td>
    </tr>

    <tr>
    <td>
    <font size=5px> <b>Comparison between Baselines</b></font><br/><br/>
    <font size=3px>
    We carry out our experiments on four tasks from Maniskill2.
    Here every task has key states aligning with semantic intuition provided by CoTPC research.<br/><br/>
    For methods which do not use key states,
    we only give the results of decision transformer,for it performs the best.
    Other baselines here use different methods to label out key states,
    which do not necessarily have to do with something similar to semantic concepts.
    We can see that the performance of our method is superior comparing to other key states discovery methods.
    </font>
    </td>
    <td class="first-column">
    <img src="imgs/main_results.png" width="600px"/>
    </td>
    </tr>
    
    </table>
    <!-- Experiments End-->

    </table>
    <br/>
    <!-- Introduction End-->

    <!-- Experiments -->
    <table>

    <tr>
    <th colspan="2">
    <font size=6px>Aligning with Our Intuition</font>
    </th>
    </tr>

    <tr>
    <td>
    <font size=5px> <b>Human Intuition Evaluation</b></font><br/><br/>
    <font size=3px>
    Based on our interest of similarity between concepts discovered by InfoCon and human's concepts,
    we define Human Intuition Score (HIS) that roughly evaluate the similarity of key states comparing to ground truth.
    HIS calculates the distance of the nearest predicted key states after each ground truth key states with respect to temporal order.
    As showing in the examples.
    We give the HIS score of the baselines that can label out key state, comparing with their manipulation task success rate,
    we find that human intuition score seems to have weak relation with the CoTPC policies performance.
    </font>
    </td>
    <td class="first-column">
    <img src="imgs/his.png" width="600px"/><br/><br/>
    <img src="imgs/his_result.png" width="600px"/>
    </td>
    </tr>

    <tr>
    <td>
    <font size=5px> <b>Assigning Concepts</b></font><br/><br/>
    <font size=3px>
    we also carry out a detailed alignment process on task Peg Insertion to further compare the concepts discovered by InfoCon.
    We found that InfoCon manage to discover some key states ignored by human label-ers.
    Although we may not be able to describe the new key states with every detail,
    they are still reasonable based on the explainable part and more importantly,
    as shown in the experiments, they are more helpful for downstream task learning.
    So, for extracting and discovering knowledge,
    InfoCon have the great potential of discover what we've ignored and what is new towards us.  
        
    </font>
    </td>
    <td class="first-column">
    <img src="imgs/assign_concept.png" width="600px"/>
    </td>
    </tr>

    </table>

    </body>
</html>
